{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cK5HM--PcnQ"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsJYnoPUQHBS",
        "outputId": "7169dc74-b319-4117-fdd4-bb31515ed8a2"
      },
      "source": [
        "# On ne garde que les n=1000 mots les plus fréquents\n",
        "nb_mots_total = 1000\n",
        "(X_train_data, Y_train), (X_test_data, Y_test) = imdb.load_data(num_words = nb_mots_total)\n",
        "print(X_train_data[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 715, 8, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 775, 7, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 656, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 625, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyoOxp9GQSBK"
      },
      "source": [
        "# Partie A bis. Afficher d'un texte\n",
        "# Afficher une critique et sa note\n",
        "def affiche_texte(num):\n",
        "  index_mots = imdb.get_word_index()\n",
        "  index_mots_inverse = dict([(value, key) for (key, value) in index_mots.items()])\n",
        "  critique_mots = ' '.join([index_mots_inverse.get(i - 3, '??') for i in X_train_data[num]])\n",
        "\n",
        "  print(\"Critique :\\n\", critique_mots)\n",
        "  print(\"Note 0 (négatif) ou 1 (positif) ? :\", Y_train[num])\n",
        "  print(\"Critique (sous forme brute) :\\n\", X_train_data[num])\n",
        "  return\n",
        "affiche_texte(123) # affichage de la critique numéro 123"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok96onFpRBQA"
      },
      "source": [
        "# Partie A ter. Données sous forme de vecteurs\n",
        "def vectorisation_critiques(X_data):\n",
        "  vecteurs = np.zeros((len(X_data), nb_mots_total))\n",
        "  for i in range(len(X_data)):\n",
        "    for c in X_data[i]:\n",
        "      vecteurs[i,c] = 1.0\n",
        "  return vecteurs\n",
        "  \n",
        "X_train = vectorisation_critiques(X_train_data)\n",
        "X_test = vectorisation_critiques(X_test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOHDRoilRHOg"
      },
      "source": [
        "# Partie B. Réseau\n",
        "modele = Sequential()\n",
        "p = 5\n",
        "modele.add(Dense(p, input_dim=nb_mots_total, activation='relu'))\n",
        "modele.add(Dense(p, activation='relu'))\n",
        "modele.add(Dense(p, activation='relu'))\n",
        "modele.add(Dense(1, activation='sigmoid'))\n",
        "modele.compile(loss='binary_crossentropy',\n",
        "optimizer='sgd',\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFcLYFVRRL9B"
      },
      "source": [
        "# Partie C. Apprentissage\n",
        "modele.fit(X_train, Y_train, epochs=10, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2zRblJGRS_y",
        "outputId": "22b187f4-3109-4934-e944-1fe6aa600ea3"
      },
      "source": [
        "# Partie D. Résultats\n",
        "Y_predict = modele.predict(X_test)\n",
        "print(Y_predict[1])\n",
        "print(X_train_data[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.99486923]\n",
            "[1, 194, 2, 194, 2, 78, 228, 5, 6, 2, 2, 2, 134, 26, 4, 715, 8, 118, 2, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 2, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2, 2, 5, 647, 4, 116, 9, 35, 2, 4, 229, 9, 340, 2, 4, 118, 9, 4, 130, 2, 19, 4, 2, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 2, 2, 398, 4, 2, 26, 2, 5, 163, 11, 2, 2, 4, 2, 9, 194, 775, 7, 2, 2, 349, 2, 148, 605, 2, 2, 15, 123, 125, 68, 2, 2, 15, 349, 165, 2, 98, 5, 4, 228, 9, 43, 2, 2, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 2, 228, 2, 5, 2, 656, 245, 2, 5, 4, 2, 131, 152, 491, 18, 2, 32, 2, 2, 14, 9, 6, 371, 78, 22, 625, 64, 2, 9, 8, 168, 145, 23, 4, 2, 15, 16, 4, 2, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n"
          ]
        }
      ]
    }
  ]
}